# Week 04

- Lemmatisation issues: US treated as a pronoun by spaCy
    - Could not find much information on how to handle this online
    - Decided to just exclude 'us' from the lemmatisation process
    - Maybe something more sophisticated, robust should be implemented in the future

- Figuring out how to remove punctuation:
    - Remove all of it?
    - What should it be replaced with: spaces or blanks?
    - Decided on spaces, because of the stopwords in NLTK's library, which expects a split of words with apostrophes
        - But made sure to remove multiple and dangling spaces
- Stop words removal?:
    - Remove all in NLTK's list, what about not, no and other stopwords with negative connotations?
    - For now all have been removed
- Pre-processing ordering?
    - to_lowercase, punctuation removal, stopword removel and then lemmatisation
- Any other techniques I should be considering for pre-processing?
- Balancing my learning against working on implementing the project, any advice?
- Not sure if I should be using all these pre-processing techniques?
- Do you know why there are bs in the DJIA dataset, I decided to remove them because I don't think it was useful to have them
- Next Sprint? Sentiment Analysis
- You never replied to my email?
- Getting a bit stressed, feels like the project is moving a bit slow, but I think that is because of the learning part into Python, NLP, etc.
- [ ]  Do you know of any specific work or papers that have focused on the dataset you provided me? Or where I could find the work?
- [ ]  Do you want to read my write-up on the methodology, when it is complete?